{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75df666",
   "metadata": {},
   "source": [
    "# Machine Learning Challenge - Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e023223",
   "metadata": {},
   "source": [
    "Semua mengenai Kaggle Challenge dapat diakses [di sini](https://www.kaggle.com/competitions/machine-learning-challenge-kaggle-competition/overview). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80082a98",
   "metadata": {},
   "source": [
    "## Latar Belakang\n",
    "Pak Mulyono adalah seorang ayah yang ingin memastikan anak-anaknya mendapatkan hasil akademik terbaik selama menempuh pendidikan di Singapura. Namun, karena kesibukannya mengurus berbagai bisnis dan proyek nasional seperti MBG, Food Estate, dan IKN bersama El Gemoy, beliau tidak memiliki cukup waktu untuk menganalisis data akademik anak-anaknya secara manual.    \n",
    "\n",
    "Salah satu anaknya, Fufufafa, mengusulkan untuk menggunakan teknologi kecerdasan buatan (AI) guna memprediksi nilai kuliah mereka secara otomatis dan akurat. Dengan bantuan siswa dari Purwadhika JCDS-2804, sebuah model machine learning diharapkan dapat dibangun untuk membantu Pak Mulyono dalam mengawasi performa akademik anak-anaknya tanpa mengganggu jadwal sibuknya.\n",
    "\n",
    "---\n",
    "\n",
    "## Permasalahan\n",
    "\n",
    "Pak Mulyono ingin mengetahui **nilai akhir (Grade)** anak-anaknya di kuliah tanpa harus mengecek satu per satu secara manual. Data nilai tidak langsung tersedia, dan perlu diprediksi berdasarkan berbagai data pendukung. Oleh karena itu, dibutuhkan **sebuah model prediktif** berbasis Machine Learning untuk membantu memperkirakan nilai mereka secara cepat, akurat, dan efisien.\n",
    "\n",
    "---\n",
    "\n",
    "## Tujuan\n",
    "\n",
    "Proyek ini bertujuan untuk:\n",
    "\n",
    "1. **Membangun model klasifikasi** menggunakan algoritma Machine Learning untuk memprediksi nilai akhir (Grade) siswa berdasarkan data karakteristik akademik dan non-akademik.\n",
    "2. **Mengevaluasi performa model** menggunakan metrik yang sesuai (misalnya akurasi, f1-score) untuk memastikan kualitas prediksi.\n",
    "3. Memberikan **insight fitur-fitur penting** yang paling memengaruhi nilai akhir siswa.\n",
    "4. Menghasilkan output prediksi untuk data siswa yang belum diketahui nilainya, sehingga Pak Mulyono dapat memantau perkembangan akademik anak-anaknya dengan praktis.\n",
    "\n",
    "> Dengan adanya model ini, diharapkan proses pemantauan nilai menjadi lebih modern, terautomasi, dan relevan dengan kebutuhan zaman.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28828157",
   "metadata": {},
   "source": [
    "## Deskripsi Kolom Dataset\n",
    "\n",
    "| **Kolom**                     | **Deskripsi**                                                                 |\n",
    "|------------------------------|-------------------------------------------------------------------------------|\n",
    "| **Student_ID**               | Identifikasi unik untuk setiap mahasiswa.                                     |\n",
    "| **First_Name**               | Nama depan mahasiswa.                                                        |\n",
    "| **Last_Name**                | Nama belakang mahasiswa.                                                     |\n",
    "| **Email**                    | Alamat email mahasiswa (dapat dianonimkan).                                  |\n",
    "| **Gender**                   | Jenis kelamin mahasiswa (Male, Female, Other).                     |\n",
    "| **Age**                      | Usia mahasiswa.                                                              |\n",
    "| **Department**               | Jurusan atau departemen tempat mahasiswa belajar (misalnya: Engineering, Business). |\n",
    "| **Attendance (%)**           | Persentase kehadiran mahasiswa (0–100%).                                     |\n",
    "| **Midterm_Score**            | Nilai ujian tengah semester (skala 100).                                      |\n",
    "| **Final_Score**              | Nilai ujian akhir semester (skala 100).                                       |\n",
    "| **Assignments_Avg**          | Rata-rata nilai tugas (skala 100).                                            |\n",
    "| **Quizzes_Avg**              | Rata-rata nilai kuis (skala 100).                                             |\n",
    "| **Participation_Score**      | Nilai partisipasi kelas (skala 0–10).                                        |\n",
    "| **Projects_Score**           | Nilai proyek akhir (skala 100).                                               |\n",
    "| **Total_Score**              | Jumlah total nilai akhir.                                   |\n",
    "| **Grade**                    | Nilai akhir mahasiswa (1 = Lulus (A–C), 0 = Tidak Lulus (D–F)).              |\n",
    "| **Study_Hours_per_Week**     | Rata-rata jam belajar mahasiswa per minggu.                                  |\n",
    "| **Extracurricular_Activities** | Partisipasi dalam kegiatan ekstrakurikuler (Yes/No).                     |\n",
    "| **Internet_Access_at_Home**  | Akses internet di rumah (Yes/No).                                          |\n",
    "| **Parent_Education_Level**   | Tingkat pendidikan tertinggi orang tua (None, High School, Bachelor's, Master's, PhD).     |\n",
    "| **Family_Income_Level**      | Tingkat pendapatan keluarga (Low, Medium, High).                      |\n",
    "| **Stress_Level (1-10)**      | Tingkat stres berdasarkan persepsi diri (1 = Rendah, 10 = Tinggi).           |\n",
    "| **Sleep_Hours_per_Night**    | Rata-rata jam tidur per malam.                                               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897da2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat model dari train, prediksi grade pada data test, gabungkan hasil prediksi dgn kolom student id data test, simpan csv lalu upload ke kaggle untuk dihitung akurasinya oleh mereka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452ec9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ff586",
   "metadata": {},
   "source": [
    "### percobaan 1 (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c36a74ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.59        83\n",
      "           1       0.73      0.78      0.76       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.68      0.67      0.68       210\n",
      "weighted avg       0.69      0.70      0.69       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Fitur dan Target\n",
    "X = df_train.drop(columns='Grade') \n",
    "y = df_train['Grade']            \n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "# penggunaan .tolist() tdk wajib tapi disarankan \n",
    "# .columns menghasilkan objek index yg mirip list, tapi menambahkan .tolist() mengubahnya jd list asli - shg lebih fleksibel saat digunakan dlm pipeline dkk yg hanya menerima list\n",
    "\n",
    "# Split train & validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "# dilakukan setelah deteksi krn bisa jadi ada kolom kategorikal yg hanya ada di val, shg jika dideteksi setelah split maka pipeline tdk tau cara menghandlenya\n",
    "\n",
    "# 2. Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputing missing values\n",
    "    ('scaler', StandardScaler())  # Standardizing features\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputing missing categorical data\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # OneHotEncoding\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Pipeline Model\n",
    "model = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit Model pada Data Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi di data validasi\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# 11. Prediksi data test (tidak perlu fit ulang karena preprocessing sudah otomatis)\n",
    "test_pred = model.predict(df_test)\n",
    "\n",
    "# 12. Buat file submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "# submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a42f1",
   "metadata": {},
   "source": [
    "### percobaan 2 (combined data test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9d6d7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6619047619047619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.48      0.54        87\n",
      "           1       0.68      0.79      0.73       123\n",
      "\n",
      "    accuracy                           0.66       210\n",
      "   macro avg       0.65      0.64      0.64       210\n",
      "weighted avg       0.66      0.66      0.65       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_df = pd.read_csv('train_data_mapped.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID dari test untuk submission \n",
    "test_ids = test_df['Student_ID'] # simpan di awal menghindari kemungkinan datanya berubah tanpa sengaja setelah digabung dgn data train\n",
    "\n",
    "# Target\n",
    "target = 'Grade'\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_cols = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "X = train_df.drop(columns=drop_cols + [target])\n",
    "y = train_df[target]\n",
    "\n",
    "# Gabungkan dengan test untuk preprocessing bareng\n",
    "X_test = test_df.drop(columns=drop_cols)\n",
    "\n",
    "# Gabung untuk preprocessing\n",
    "combined = pd.concat([X, X_test], axis=0) # karena ada kemungkinan ada nilai unik yg hanya muncul di data test, dilakukan agar preprocessing belajar dari seluruh kombinasi data\n",
    "\n",
    "# Pisahkan kolom numerik dan kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = combined.select_dtypes(include='object').columns\n",
    "\n",
    "# baseline cukup (tdk merusak, tp bisa suboptimal) untuk awal, dan bisa ditambahkan sambil pantau skor\n",
    "\n",
    "# Imputasi data numerik\n",
    "imputer_num = SimpleImputer(strategy='mean') # pakai mean dan most frequent karena ini yg plg umum untuk baseline # bisa pakai median, imputasi grouping atau model based imputation agar imputasi lebih kuat\n",
    "combined[num_cols] = imputer_num.fit_transform(combined[num_cols])\n",
    "\n",
    "# Imputasi data kategorikal\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "combined[cat_cols] = imputer_cat.fit_transform(combined[cat_cols]) # data test ikut difit (walaupun tdk ideal di dunia nyata, tapi di kaggle, test tdk punya label -aman dr kebocoran target- dan evaluasi dilakukan di kaggle server shg bisa ditoleransi)\n",
    "# fit berfungsi untuk menyimpan data dari train, dan transform berfungsi untuk mengubah data berdasarkan hasil fit\n",
    "\n",
    "# One-hot encoding untuk kolom kategorikal\n",
    "combined = pd.get_dummies(combined, columns=cat_cols)\n",
    "\n",
    "# Split kembali ke X_train dan X_test\n",
    "X_encoded = combined.iloc[:len(X)] # len(X) adalah jumlah baris awal dr data train sblm digabung (tdk perlu (+1) karena perhitungan baris dr 0)\n",
    "X_test_encoded = combined.iloc[len(X):] \n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_encoded = scaler.fit_transform(X_encoded)\n",
    "X_test_encoded = scaler.transform(X_test_encoded)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42) # dilakukan setelah preprocessing agar preprocessing bisa mempelajari keseluruhan data train dan validasi\n",
    "# data validasi diambil dr 20% data train, tidak ikut ditrain, untuk memastikan model tdk overfit dan bisa generalisasi\n",
    "# train test split tidak dilakukan di data test karena data test tdk memiliki label target\n",
    "\n",
    "# Modeling\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train) # fit disini adalah proses pelatihan model (akan mempelajari hubungan fitur dan target dan simpan info penting)\n",
    "# model ML tdk perlu transform, tapi pakai predict() untuk prediksi kelas dan predict_proba() untuk prediksi probabilitas\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_val) # evaluasi performa model, untuk melihat seberapa bagus model\n",
    "print(classification_report(y_val, y_pred)) # hanya untuk evaluasi internal, bukan skor final kaggle\n",
    "\n",
    "# Predict test data\n",
    "test_pred = model.predict(X_test_encoded) # prediksi akhir ke data uji, untuk submission csv\n",
    " \n",
    "# Submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "# submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744bc8bc",
   "metadata": {},
   "source": [
    "### percobaan 3 (combined data test, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cad8b57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.59        83\n",
      "           1       0.73      0.78      0.76       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.68      0.67      0.68       210\n",
      "weighted avg       0.69      0.70      0.69       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Buat pipeline model\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int) # None dikenali sebagai object, shg ketika digabungkan, Grade otomatis diubah menjadi object\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model dan evaluasi\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "y_pred = model_pipeline.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "# submission.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b634c3a",
   "metadata": {},
   "source": [
    "### percobaan 4 (hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "826ae48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear', 'preprocessing__num__imputer__strategy': 'median'}\n",
      "Best cross-validation score: 0.6666666666666666\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.59        83\n",
      "           1       0.73      0.78      0.76       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.68      0.67      0.68       210\n",
      "weighted avg       0.69      0.70      0.69       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Buat pipeline model\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "# Tentukan grid parameter yang ingin diuji\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],  # Regularization strength untuk Logistic Regression\n",
    "    'classifier__penalty': ['11', 'l2'],  # Regularization type (L1 atau L2)\n",
    "    'classifier__solver': ['liblinear', 'saga'],  # Solvers yang berbeda untuk Logistic Regression\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median']  # Strategi imputasi untuk kolom numerik\n",
    "}\n",
    "\n",
    "# Buat objek GridSearchCV\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = grid_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "# submission.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7757d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'preprocessing__num__imputer__strategy': 'median', 'classifier__solver': 'liblinear', 'classifier__penalty': 'l2', 'classifier__C': 0.1}\n",
      "Best cross-validation score: 0.6666666666666666\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.59        83\n",
      "           1       0.73      0.78      0.76       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.68      0.67      0.68       210\n",
      "weighted avg       0.69      0.70      0.69       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Buat pipeline model\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "# Tentukan distribusi parameter yang ingin diuji\n",
    "param_dist = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median'],\n",
    "}\n",
    "\n",
    "# Buat objek RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model_pipeline, param_dist, n_iter=100, cv=5, n_jobs=-1, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = random_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = random_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "# submission.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9dbb41",
   "metadata": {},
   "source": [
    "### percobaan 5 (ubah encoder dan scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31486c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'preprocessing__num__imputer__strategy': 'mean', 'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__C': 1}\n",
      "Best cross-validation score: 0.6761904761904762\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60        83\n",
      "           1       0.74      0.79      0.76       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.69      0.68      0.68       210\n",
      "weighted avg       0.70      0.70      0.70       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Fitur\n",
    "num_cols = ['Age', 'Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg',\n",
    "            'Quizzes_Avg', 'Participation_Score', 'Projects_Score', 'Total_Score',\n",
    "            'Study_Hours_per_Week', 'Stress_Level (1-10)', 'Sleep_Hours_per_Night']\n",
    "\n",
    "nominal_cols = ['Gender', 'Department', 'Extracurricular_Activities', 'Internet_Access_at_Home']\n",
    "ordinal_cols = ['Parent_Education_Level', 'Family_Income_Level']\n",
    "\n",
    "# Ordinal encoder mapping\n",
    "education_order = ['None', 'High School', \"Bachelor's\", \"Master's\", 'PhD']\n",
    "income_order = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(categories=[education_order, income_order]))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('nom', nominal_pipeline, nominal_cols),\n",
    "    ('ord', ordinal_pipeline, ordinal_cols)\n",
    "])\n",
    "\n",
    "# Buat pipeline model\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "# Tentukan distribusi parameter yang ingin diuji\n",
    "param_dist = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median'],\n",
    "}\n",
    "\n",
    "# Buat objek RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model_pipeline, param_dist, n_iter=100, cv=5, n_jobs=-1, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = random_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = random_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "# submission.to_csv('submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384c06e",
   "metadata": {},
   "source": [
    "### percobaan 6 (feature selection ubah encoder scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb53d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'preprocessing__num__imputer__strategy': 'mean', 'feature_selection__k': 'all', 'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__C': 1}\n",
      "Best cross-validation score: 0.6761904761904762\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60        83\n",
      "           1       0.74      0.79      0.76       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.69      0.68      0.68       210\n",
      "weighted avg       0.70      0.70      0.70       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Fitur\n",
    "num_cols = ['Age', 'Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg',\n",
    "            'Quizzes_Avg', 'Participation_Score', 'Projects_Score', 'Total_Score',\n",
    "            'Study_Hours_per_Week', 'Stress_Level (1-10)', 'Sleep_Hours_per_Night']\n",
    "\n",
    "nominal_cols = ['Gender', 'Department', 'Extracurricular_Activities', 'Internet_Access_at_Home']\n",
    "ordinal_cols = ['Parent_Education_Level', 'Family_Income_Level']\n",
    "\n",
    "# Ordinal encoder mapping\n",
    "education_order = ['None', 'High School', \"Bachelor's\", \"Master's\", 'PhD']\n",
    "income_order = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(categories=[education_order, income_order]))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('nom', nominal_pipeline, nominal_cols),\n",
    "    ('ord', ordinal_pipeline, ordinal_cols)\n",
    "])\n",
    "\n",
    "# Pipeline with feature selection\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),  # jumlah fitur dipilih\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Tentukan distribusi parameter yang ingin diuji\n",
    "param_dist = {\n",
    "    'feature_selection__k': [10, 15, 20, 'all'],\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median'],\n",
    "}\n",
    "\n",
    "# Buat objek RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model_pipeline, param_dist, n_iter=100, cv=5, n_jobs=-1, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = random_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = random_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e8d6e",
   "metadata": {},
   "source": [
    "### percobaan 7 (feature selection tanpa ubah preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "079bd142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga', 'feature_selection__k': 20, 'preprocessing__num__imputer__strategy': 'mean'}\n",
      "Best cross-validation score: 0.6738095238095237\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60        83\n",
      "           1       0.74      0.80      0.77       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.69      0.68      0.68       210\n",
      "weighted avg       0.70      0.70      0.70       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Pipeline with feature selection\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),  # jumlah fitur dipilih\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Tentukan grid parameter yang ingin diuji\n",
    "param_grid = {\n",
    "    'feature_selection__k': [10, 15, 20, 'all'],\n",
    "    'classifier__C': [0.1, 1, 10, 100],  # Regularization strength untuk Logistic Regression\n",
    "    'classifier__penalty': ['11', 'l2'],  # Regularization type (L1 atau L2)\n",
    "    'classifier__solver': ['liblinear', 'saga'],  # Solvers yang berbeda untuk Logistic Regression\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median']  # Strategi imputasi untuk kolom numerik\n",
    "}\n",
    "\n",
    "# Buat objek GridSearchCV\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = grid_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission7_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4800e895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'preprocessing__num__imputer__strategy': 'mean', 'feature_selection__k': 20, 'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__C': 0.1}\n",
      "Best cross-validation score: 0.6738095238095237\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60        83\n",
      "           1       0.74      0.80      0.77       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.69      0.68      0.68       210\n",
      "weighted avg       0.70      0.70      0.70       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Pipeline with feature selection\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=20)),  # jumlah fitur dipilih\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Tentukan distribusi parameter yang ingin diuji\n",
    "param_dist = {\n",
    "    'feature_selection__k': [10, 15, 20, 'all'],\n",
    "    'classifier__C': [0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median'],\n",
    "}\n",
    "\n",
    "# Buat objek RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model_pipeline, param_dist, n_iter=100, cv=5, n_jobs=-1, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = random_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = random_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "# submission.to_csv('submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93577b",
   "metadata": {},
   "source": [
    "# percobaan 8 (p6+random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fcbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100, 'preprocessing__num__imputer__strategy': 'mean'}\n",
      "Best cross-validation score: 0.6547619047619048\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61        83\n",
      "           1       0.74      0.76      0.75       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.68      0.68      0.68       210\n",
      "weighted avg       0.69      0.70      0.69       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# GridSearch param untuk Random Forest\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2],\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median']\n",
    "}\n",
    "\n",
    "# Buat objek GridSearchCV\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = grid_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "## submission.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952ee974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100, 'preprocessing__num__imputer__strategy': 'mean'}\n",
      "Best cross-validation score: 0.6547619047619048\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61        83\n",
      "           1       0.74      0.76      0.75       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.68      0.68      0.68       210\n",
      "weighted avg       0.69      0.70      0.69       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Buat pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# GridSearch param untuk Random Forest\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median']\n",
    "}\n",
    "\n",
    "\n",
    "# Buat objek GridSearchCV\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # Pastikan target Grade bertipe int\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluasi pada validation set\n",
    "y_pred = grid_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6899d70",
   "metadata": {},
   "source": [
    "# paling tinggi :) (random forest + tanpa scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2320cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100, 'preprocessing__num__imputer__strategy': 'mean'}\n",
      "Best cross-validation score: 0.6547619047619048\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.59        83\n",
      "           1       0.73      0.78      0.76       127\n",
      "\n",
      "    accuracy                           0.70       210\n",
      "   macro avg       0.68      0.67      0.68       210\n",
      "weighted avg       0.69      0.70      0.69       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv('train_data_mapped.csv')\n",
    "df_test = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Simpan Student_ID untuk submission\n",
    "test_ids = df_test['Student_ID']\n",
    "\n",
    "# Drop kolom non-predictor\n",
    "drop_columns = ['Student_ID', 'First_Name', 'Last_Name', 'Email']\n",
    "df_train = df_train.drop(columns=drop_columns)\n",
    "df_test = df_test.drop(columns=drop_columns)\n",
    "\n",
    "# Tambahkan placeholder Grade untuk test agar bisa digabung\n",
    "df_test['Grade'] = None\n",
    "\n",
    "# Gabungkan train dan test\n",
    "combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Deteksi kolom numerik & kategorikal\n",
    "num_cols = combined.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = combined.select_dtypes(include=['object']).drop('Grade', axis=1).columns.tolist()\n",
    "\n",
    "# Pipeline numerik & kategorik\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing dalam ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# GridSearch param untuk Random Forest\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'preprocessing__num__imputer__strategy': ['mean', 'median']\n",
    "}\n",
    "\n",
    "\n",
    "# Buat objek GridSearchCV\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Pisahkan kembali data train dan data test\n",
    "combined_train = combined[combined['Grade'].notnull()]\n",
    "combined_train['Grade'] = combined_train['Grade'].astype(int)  # None dikenali sebagai object, shg ketika digabungkan, Grade otomatis diubah menjadi object\n",
    "combined_test = combined[combined['Grade'].isnull()]\n",
    "\n",
    "# Fitur dan Target\n",
    "X = combined_train.drop(columns='Grade')\n",
    "y = combined_train['Grade']\n",
    "X_test = combined_test.drop(columns='Grade')\n",
    "\n",
    "# Split train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lihat hasil terbaik\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluasi validation set\n",
    "y_pred = grid_search.predict(X_val)\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prediksi data test\n",
    "test_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'Student_ID': test_ids,\n",
    "    'Grade': test_pred\n",
    "})\n",
    "\n",
    "# submission.to_csv('submission8_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
